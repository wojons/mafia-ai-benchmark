# Mafia AI Benchmark Environment Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# LLM Provider API Keys
# =============================================================================

# OpenRouter API Key (OpenAI-compatible endpoint - RECOMMENDED)
# Get your key at: https://openrouter.ai/keys
OPENAI_API_KEY=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

# Alternative providers (optional)
# ANTHROPIC_API_KEY=sk-ant-api03-xxxxxxxxxxxxxxxxxxxx
# GOOGLE_API_KEY=xxxxxxxxxxxxxxxxxxxx
# DEEPSEEK_API_KEY=xxxxxxxxxxxxxxxxxxxx
# GROQ_API_KEY=gsk_xxxxxxxxxxxxxxxxxxxx
# META_API_KEY=xxxxxxxxxxxxxxxxxxxx
# MISTRAL_API_KEY=xxxxxxxxxxxxxxxxxxxx
# XAI_API_KEY=xxxxxxxxxxxxxxxxxxxx
# QWEN_API_KEY=xxxxxxxxxxxxxxxxxxxx

# =============================================================================
# Default Model Configuration
# =============================================================================

# Default model for all players (format: provider/model)
# Options: openai/gpt-4o-mini, openai/gpt-4o, openai/gpt-4
#         anthropic/claude-3-haiku, anthropic/claude-3-sonnet, anthropic/claude-3-opus
#         google/gemini-1.5-flash, google/gemini-1.5-pro
DEFAULT_MODEL=openai/gpt-4o-mini

# Role-specific model overrides (format: provider/model)
# Leave empty to use DEFAULT_MODEL
MAFIA_MODEL=
DOCTOR_MODEL=
SHERIFF_MODEL=
VIGILANTE_MODEL=
VILLAGER_MODEL=

# Model settings
DEFAULT_TEMPERATURE=0.7
DEFAULT_MAX_TOKENS=500

# =============================================================================
# Local LLM Providers (optional)
# =============================================================================

# Ollama (local)
# OLLAMA_BASE_URL=http://localhost:11434/v1
# OLLAMA_MODEL=llama2

# LM Studio (local)
# LM_STUDIO_BASE_URL=http://localhost:1234/v1
# LM_STUDIO_MODEL=meta-llama-llama-2-7b-chat

# =============================================================================
# Game Settings
# =============================================================================

# Default number of players
DEFAULT_PLAYERS=10

# Mafia count (leave empty for auto: floor(players/4))
MAFIA_COUNT=

# Special role counts
DOCTOR_COUNT=1
SHERIFF_COUNT=1
VIGILANTE_COUNT=1

# Messaging limits
MAFIA_MESSAGES_PER_PLAYER=3
MAFIA_MAX_MESSAGES=10
TOWN_MESSAGES_PER_PLAYER=2
TOWN_MAX_MESSAGES=15

# Day settings
DAY_DISCUSSION_ROUNDS=1
VOTING_ENABLED=true
NIGHT_PHASE_ENABLED=true

# Persona system
PERSONA_ENABLED=true

# =============================================================================
# Server Configuration
# =============================================================================

# HTTP server port
PORT=3000

# WebSocket server port
WS_PORT=3001

# Database path
DB_PATH=./data/mafia.db

# =============================================================================
# Development & Debugging
# =============================================================================

NODE_ENV=development
DEBUG=false

# Logging level: debug, info, warn, error
LOG_LEVEL=info

# =============================================================================
# Model Provider Endpoints (override if needed)
# =============================================================================

# OpenAI
OPENAI_BASE_URL=https://openrouter.ai/api/v1

# Anthropic
ANTHROPIC_BASE_URL=https://api.anthropic.com/v1

# Google
GOOGLE_BASE_URL=https://generativelanguage.googleapis.com/v1

# DeepSeek
DEEPSEEK_BASE_URL=https://api.deepseek.com/v1

# Groq
GROQ_BASE_URL=https://api.groq.com/openai/v1

# Meta
META_BASE_URL=https://api.meta.com/v1

# Mistral
MISTRAL_BASE_URL=https://api.mistral.ai/v1

# XAI
XAI_BASE_URL=https://api.x.ai/v1

# Qwen
QWEN_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1

# =============================================================================
# Rate Limiting
# =============================================================================

# Requests per minute per player
RATE_LIMIT_PER_MINUTE=60

# Tokens per minute (0 = unlimited)
TOKENS_PER_MINUTE=0

# =============================================================================
# Cost Tracking
# =============================================================================

# Track costs per model
TRACK_COSTS=true

# =============================================================================
# IMPORTANT: Pricing Information
# =============================================================================
# 
# Model pricing is now fetched DYNAMICALLY from the models.dev API:
# https://models.dev/api.json
#
# NO static prices are configured in this file anymore.
# All pricing comes from the API in real-time.
#
# If a model is not found in the API, its price is set to:
# NO_PRICING_MARKER = -6.66
#
# This ensures accurate, up-to-date pricing for all models.
#
# Popular models and their current API prices:
# - gpt-4o-mini:      $0.15/M in, $0.60/M out
# - gpt-4o:           $2.50/M in, $10.00/M out
# - claude-sonnet-4:  $3.00/M in, $15.00/M out
# - claude-haiku-4:   $1.00/M in, $5.00/M out
# - gemini-2.5-flash: $0.075/M in, $0.30/M out
# - gemini-2.5-pro:   $1.25/M in, $10.00/M out
# - llama-3.3-70b:    $0.59/M in, $0.79/M out
# - deepseek-chat:    $0.28/M in, $0.42/M out
# - grok-3:           $3.00/M in, $15.00/M out
#
# You can check available models and their prices by running:
# node -e "const {getModelPricing} = require('./packages/shared/dist/providers/model-metadata.js'); getModelPricing('gpt-4o-mini').then(console.log);"
#
